{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#need Ngl for Charlie's function to work, but can't seem to import correctly. May need to change environment\n",
    "#import Ngl\n",
    "import esmlab\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#note: Dan uses \"import glob\" -- glob handles wildcards better than xarray for reading in multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import intake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_id</th>\n",
       "      <th>institution_id</th>\n",
       "      <th>source_id</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>member_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>grid_label</th>\n",
       "      <th>dcpp_init_year</th>\n",
       "      <th>version</th>\n",
       "      <th>time_range</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>hfss</td>\n",
       "      <td>gn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v20190624</td>\n",
       "      <td>201501-205512</td>\n",
       "      <td>/glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>pr</td>\n",
       "      <td>gn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v20190624</td>\n",
       "      <td>201501-205512</td>\n",
       "      <td>/glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>rsus</td>\n",
       "      <td>gn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v20190624</td>\n",
       "      <td>201501-205512</td>\n",
       "      <td>/glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>tas</td>\n",
       "      <td>gn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v20190624</td>\n",
       "      <td>201501-205512</td>\n",
       "      <td>/glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AerChemMIP</td>\n",
       "      <td>BCC</td>\n",
       "      <td>BCC-ESM1</td>\n",
       "      <td>ssp370</td>\n",
       "      <td>r1i1p1f1</td>\n",
       "      <td>Amon</td>\n",
       "      <td>ts</td>\n",
       "      <td>gn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>v20190624</td>\n",
       "      <td>201501-205512</td>\n",
       "      <td>/glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_id institution_id source_id experiment_id member_id table_id  \\\n",
       "0  AerChemMIP            BCC  BCC-ESM1        ssp370  r1i1p1f1     Amon   \n",
       "1  AerChemMIP            BCC  BCC-ESM1        ssp370  r1i1p1f1     Amon   \n",
       "2  AerChemMIP            BCC  BCC-ESM1        ssp370  r1i1p1f1     Amon   \n",
       "3  AerChemMIP            BCC  BCC-ESM1        ssp370  r1i1p1f1     Amon   \n",
       "4  AerChemMIP            BCC  BCC-ESM1        ssp370  r1i1p1f1     Amon   \n",
       "\n",
       "  variable_id grid_label  dcpp_init_year    version     time_range  \\\n",
       "0        hfss         gn             NaN  v20190624  201501-205512   \n",
       "1          pr         gn             NaN  v20190624  201501-205512   \n",
       "2        rsus         gn             NaN  v20190624  201501-205512   \n",
       "3         tas         gn             NaN  v20190624  201501-205512   \n",
       "4          ts         gn             NaN  v20190624  201501-205512   \n",
       "\n",
       "                                                path  \n",
       "0  /glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...  \n",
       "1  /glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...  \n",
       "2  /glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...  \n",
       "3  /glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...  \n",
       "4  /glade/collections/cmip/CMIP6/AerChemMIP/BCC/B...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catalog = intake.open_esm_datastore(\"/glade/collections/cmip/catalog/intake-esm-datastore/catalogs/glade-cmip6.json\")\n",
    "catalog.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_sr = catalog.search(experiment_id=['historical'], variable_id='co2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "test_sr.unique('source_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#don't really understand this output\n",
    "test_sr.unique('member_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading catalog to load CO2 values for CMIP6 models\n",
    "Multiple configurations of BCC and CESM available. Choosing one narrows models to 4.\n",
    "Difficult to tell how many models have multiple ensemble members, so only using first member"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = 'Amon'\n",
    "var = 'co2'\n",
    "# note that there are different numbers of model output available depending on options used for source_id and member_id\n",
    "# should I consider using multiple ensemble members per model? multiple model configurations per model?\n",
    "#member_id = [\"r1i1p1f1\",\"r2i1p1f1\",\"r3i1p1f1\",\"r4i1p1f1\",\"r5i1p1f1\",\"r6i1p1f1\"]\n",
    "# note that MIROC doesn't show up here because it's member_id = r1i2p1f1. Not sure why this is numbered differently\n",
    "cat = catalog.search(experiment_id=['historical'], variable_id=var,\n",
    "#                        source_id=test_sr.unique('source_id')['source_id']['values'], \n",
    "                        source_id=['CESM2','BCC-ESM1','MRI-ESM2-0','GFDL-ESM4'], \n",
    "#                        table_id=table_id, member_id =member_id)\n",
    "                        table_id=table_id, member_id =\"r1i1p1f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BCC-ESM1', 'CESM2', 'GFDL-ESM4', 'MRI-ESM2-0']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.unique('source_id')['source_id']['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['r1i1p1f1']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.unique('member_id')['member_id']['values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grid_label': {'count': 2, 'values': ['gn', 'gr1']}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.unique('grid_label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data to dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4/4 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "co2_ds = cat.to_dataset_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['CMIP.MRI.MRI-ESM2-0.historical.Amon.gn', 'CMIP.NOAA-GFDL.GFDL-ESM4.historical.Amon.gr1', 'CMIP.BCC.BCC-ESM1.historical.Amon.gn', 'CMIP.NCAR.CESM2.historical.Amon.gn'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co2_ds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "#### Note: Not all output is available on CMIP6 archive, so ignoring next 4 code blocks for now\n",
    "### Get the fixed variables output, only available for historical simulations (gridcell area, landfrac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sr_fx_ctrl_vars = catalog.search(table_id = ['fx'], source_id = cat.unique('source_id')['source_id']['values'], \n",
    "                                 member_id = cat.unique('member_id')['member_id']['values'], \n",
    "                                 experiment_id = 'historical', variable_id = ['areacella', 'sftlf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "sr_fx_ctrl_vars.unique('grid_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fx_ds = sr_fx_ctrl_vars.to_dataset_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#what happened to BCC? Doesn't seem to have fx (also checked /glade/collections/cmip/CMIP6/CMIP/BCC and online archive)\n",
    "fx_ds.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   \n",
    "### Starting data analysis\n",
    "###   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating amplitude for each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 64, lon: 128, member_id: 1, plev: 19, time: 165)\n",
      "Coordinates:\n",
      "  * time       (time) datetime64[ns] 1850-12-31 1851-12-31 ... 2014-12-31\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(64, 2), meta=np.ndarray>\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(128, 2), meta=np.ndarray>\n",
      "  * lat        (lat) float64 -87.86 -85.1 -82.31 -79.53 ... 82.31 85.1 87.86\n",
      "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
      "  * plev       (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 1e+03 500.0 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    co2        (time, member_id, plev, lat, lon) float32 dask.array<chunksize=(1, 1, 19, 64, 128), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 180, lon: 288, member_id: 1, plev: 19, time: 165)\n",
      "Coordinates:\n",
      "  * time       (time) object 1850-12-31 00:00:00 ... 2014-12-31 00:00:00\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(180, 2), meta=np.ndarray>\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(288, 2), meta=np.ndarray>\n",
      "  * lat        (lat) float64 -89.5 -88.5 -87.5 -86.5 ... 86.5 87.5 88.5 89.5\n",
      "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
      "  * bnds       (bnds) float64 1.0 2.0\n",
      "  * plev       (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 1e+03 500.0 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Data variables:\n",
      "    co2        (time, member_id, plev, lat, lon) float32 dask.array<chunksize=(1, 1, 19, 180, 288), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 64, lon: 128, member_id: 1, plev: 19, time: 165)\n",
      "Coordinates:\n",
      "  * time       (time) object 1850-12-31 00:00:00 ... 2014-12-31 00:00:00\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(64, 2), meta=np.ndarray>\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(128, 2), meta=np.ndarray>\n",
      "  * lat        (lat) float64 -87.86 -85.1 -82.31 -79.53 ... 82.31 85.1 87.86\n",
      "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
      "  * plev       (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 1e+03 500.0 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    co2        (time, member_id, plev, lat, lon) float32 dask.array<chunksize=(1, 1, 19, 64, 128), meta=np.ndarray>\n",
      "<xarray.Dataset>\n",
      "Dimensions:    (lat: 192, lon: 288, member_id: 1, nbnd: 2, plev: 19, time: 165)\n",
      "Coordinates:\n",
      "  * time       (time) object 1850-12-31 00:00:00 ... 2014-12-31 00:00:00\n",
      "    lat_bnds   (lat, nbnd) float64 dask.array<chunksize=(192, 2), meta=np.ndarray>\n",
      "    lon_bnds   (lon, nbnd) float64 dask.array<chunksize=(288, 2), meta=np.ndarray>\n",
      "  * lat        (lat) float64 -90.0 -89.06 -88.12 -87.17 ... 88.12 89.06 90.0\n",
      "  * lon        (lon) float64 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "  * plev       (plev) float64 1e+05 9.25e+04 8.5e+04 7e+04 ... 1e+03 500.0 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: nbnd\n",
      "Data variables:\n",
      "    co2        (time, member_id, plev, lat, lon) float32 dask.array<chunksize=(1, 1, 19, 192, 288), meta=np.ndarray>\n"
     ]
    }
   ],
   "source": [
    "for sim_name, data in co2_ds.items():\n",
    "# set_coords based on M. Long's suggestion so that subtraction not applied to coordinate variables\n",
    "# works on on datasets, but not on the dictionary.\n",
    "    data    = data.set_coords(['time_bnds', 'lat_bnds', 'lon_bnds'])\n",
    "#    datamax = data.resample(time=\"Y\").max()\n",
    "#    datamin = data.resample(time=\"Y\").min()\n",
    "#    co2amp  = datamax.co2 - datamin.co2\n",
    "    co2amp  = data.resample(time=\"Y\").max() - data.resample(time=\"Y\").min()\n",
    "    print(co2amp)\n",
    "    co2_ds[sim_name] = co2amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Note: This doesn't work due to calendar mismatches.\n",
    "# See example here for reading in a dataset: https://geocat-examples.readthedocs.io/en/latest/gallery/XY/NCL_xy_18.html#sphx-glr-gallery-xy-ncl-xy-18-py\n",
    "# Not sure how to do this for reading in a dictionary\n",
    "\n",
    "#for amp_name, amp in co2_ds.items():\n",
    "#    amp_stnd = amp.sel(time=slice('1850','2014')) - amp.sel(time=slice('1850'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Weighting functions from Matt Long\n",
    "#### Grid cell area is not available for all models, so need to use sin weighting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#From Matt Long:\n",
    "def infer_lat_name(ds): \n",
    "    lat_names = ['latitude', 'lat']\n",
    "    for n in lat_names:\n",
    "        if n in ds:\n",
    "            return n\n",
    "    raise ValueError('could not determine lat name')    \n",
    "\n",
    "\n",
    "def infer_lon_name(ds):\n",
    "    lon_names = ['longitude', 'lon']\n",
    "    for n in lon_names:\n",
    "        if n in ds:\n",
    "            return n\n",
    "    raise ValueError('could not determine lon name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Also from Matt Long:\n",
    "def lat_weights_regular_grid(lat):\n",
    "    \"\"\"\n",
    "    Generate latitude weights for equally spaced (regular) global grids.\n",
    "    Weights are computed as sin(lat+dlat/2)-sin(lat-dlat/2) and sum to 2.0.\n",
    "    \"\"\"  \n",
    "    dlat = np.abs(np.diff(lat))\n",
    "    np.testing.assert_almost_equal(dlat, dlat[0])\n",
    "    w = np.abs(np.sin(np.radians(lat + dlat[0] / 2.)) - np.sin(np.radians(lat - dlat[0] / 2.)))\n",
    "\n",
    "    if np.abs(lat[0]) > 89.9999:\n",
    "        w[0] = np.abs(1. - np.sin(np.radians(np.pi / 2 - dlat[0])))\n",
    "\n",
    "    if np.abs(lat[-1]) > 89.9999:\n",
    "        w[-1] = np.abs(1. - np.sin(np.radians(np.pi / 2 - dlat[0])))\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Also from Matt Long:\n",
    "def compute_grid_area(ds, check_total=True):\n",
    "    \"\"\"Compute the area of grid cells.\"\"\"\n",
    "   \n",
    "    radius_earth = 6.37122e6 # m, radius of Earth\n",
    "    area_earth = 4.0 * np.pi * radius_earth**2 # area of earth [m^2]e\n",
    "   \n",
    "    lon_name = infer_lon_name(ds)      \n",
    "    lat_name = infer_lat_name(ds)        \n",
    "   \n",
    "    weights = lat_weights_regular_grid(ds[lat_name])\n",
    "    area = weights + 0.0 * ds[lon_name] # add 'lon' dimension\n",
    "    area = (area_earth / area.sum(dim=(lat_name, lon_name))) * area\n",
    "   \n",
    "    if check_total:\n",
    "        np.testing.assert_approx_equal(np.sum(area), area_earth)\n",
    "       \n",
    "    return xr.DataArray(area, dims=(lat_name, lon_name), attrs={'units': 'm^2', 'long_name': 'area'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Some examples from Charlie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def get_gridcell_edges(lat, lon):\n",
    "    IM = lon.shape[0]\n",
    "    JM = lat.shape[0]\n",
    "    #\n",
    "    lat_edges = np.zeros(JM+1)\n",
    "    lon_edges = np.zeros(IM+1)\n",
    "    #\n",
    "    lat_edges[0] = max(lat[0] - (lat[1] - lat[0]) / 2., -90.)\n",
    "    lat_edges[JM] = min(lat[JM-1] + (lat[JM-1] - lat[JM-2]) / 2., 90.)\n",
    "    for j in range(1,JM):\n",
    "        lat_edges[j] = (lat[j] + lat[j-1])/2.\n",
    "    #    \n",
    "    lon_edges[0] = lon[0] - (lon[1] - lon[0]) / 2.\n",
    "    lon_edges[IM] = lon[IM-1] + (lon[IM-1] - lon[IM-2]) / 2.\n",
    "    for i in range(1,IM):\n",
    "        lon_edges[i] = (lon[i] + lon[i-1])/2.\n",
    "    #\n",
    "    return lat_edges, lon_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def gridcell_areas(lat, lon, mask=None, radius=6372000., lat_edges_in=False, lon_edges_in=False):\n",
    "\n",
    "    ### assume uniform longitude spacing\n",
    "    lat_edges, lon_edges = get_gridcell_edges(lat, lon)\n",
    "    if lon_edges_in:\n",
    "        IM = lon.shape[0] - 1\n",
    "        lon_edges = lon[:]\n",
    "        res_lon = lon_edges[1] - lon_edges[0]\n",
    "    else:\n",
    "        IM = lon.shape[0]\n",
    "        res_lon = lon[1]-lon[0]\n",
    "        #\n",
    "    if lat_edges_in:\n",
    "        JM = lat.shape[0] - 1       \n",
    "        lat_edges = lat[:] \n",
    "    else:\n",
    "        JM = lat.shape[0]\n",
    "    southern_edge = np.fmax(lat_edges[0:JM], np.ones(JM)*-89.99)\n",
    "    northern_edge = np.fmin(lat_edges[1:], np.ones(JM)*89.99)\n",
    "    #\n",
    "    area = Ngl.gc_qarea(southern_edge,np.zeros(JM)-res_lon/2.,\\\n",
    "                        northern_edge,np.zeros(JM)-res_lon/2.,\\\n",
    "                        northern_edge,np.zeros(JM)+res_lon/2.,\\\n",
    "                        southern_edge,np.zeros(JM)+res_lon/2.,\\\n",
    "                        radius=radius) ### 1-D array in meters sq.\n",
    "    area_array = np.array(np.reshape(np.repeat(area,IM), [JM,IM]))\n",
    "    if not mask==None:\n",
    "        area_array = np.ma.array(area_array, mask=mask)\n",
    "    return area_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def find_closest(lats, lons, lat, lon, mask=None):\n",
    "    mindist = 1e20\n",
    "    if mask == None:\n",
    "        mask = np.zeros([len(lats), len(lons)], dtype=np.bool)\n",
    "    for i in range(len(lons)):\n",
    "        for j in range(len(lats)):\n",
    "            if not mask[j,i]:\n",
    "                dist = Ngl.gc_dist(lons[i], lats[j], lon, lat)\n",
    "                if dist < mindist:\n",
    "                    closest_i = i\n",
    "                    closest_j = j\n",
    "                    mindist = dist\n",
    "    return closest_i, closest_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_nbp = {}\n",
    "bar_nbp = {}\n",
    "nh_nbp = {}\n",
    "for sim_name, data in co2_ds.items():\n",
    "    #may want to consider also selecting the level here, but not sure correct level for mauna loa. \n",
    "    ml_nbp[sim_name] = data.sel(lat=19.5,lon=204.4, method='nearest')\n",
    "    bar_nbp[sim_name] = data.sel(lat=71.3,lon=203.4, method='nearest')\n",
    "    nh_nbp[sim_name]  = data.sel(lat=slice(30,90))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "print(ml_nbp.keys())\n",
    "print(ml_nbp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change in CO2 amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barrow\n",
    "barrow_pct_change = {}\n",
    "\n",
    "for sim_name, data in bar_nbp.items():\n",
    "    bar_co2_ds_late = (data.isel(plev=18, time=slice(163,165))).mean(dim=[\"time\"])\n",
    "    bar_co2_ds_early = (data.isel(plev=18, time=slice(107,109))).mean(dim=[\"time\"])\n",
    "    barrow_pct_change[sim_name] = ((bar_co2_ds_late - bar_co2_ds_early)/bar_co2_ds_early)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CMIP.MRI.MRI-ESM2-0.historical.Amon.gn', 'CMIP.NOAA-GFDL.GFDL-ESM4.historical.Amon.gr1', 'CMIP.BCC.BCC-ESM1.historical.Amon.gn', 'CMIP.NCAR.CESM2.historical.Amon.gn'])\n"
     ]
    }
   ],
   "source": [
    "print(barrow_pct_change.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#N. Hemisphere (45-90N)\n",
    "late_change = {}\n",
    "pct_change = {}\n",
    "\n",
    "for sim_name, data in co2_ds.items():\n",
    "    co2_ds_late = (data.isel(plev=18, lat=slice(45,90), time=slice(163,165))).mean(dim=[\"time\"])\n",
    "    co2_ds_early = (data.isel(plev=18, lat=slice(45,90), time=slice(107,109))).mean(dim=[\"time\"])\n",
    "    late_change[sim_name] = co2_ds_late\n",
    "    pct_change[sim_name] = ((co2_ds_late - co2_ds_early)/co2_ds_early)*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['CMIP.MRI.MRI-ESM2-0.historical.Amon.gn', 'CMIP.NOAA-GFDL.GFDL-ESM4.historical.Amon.gr1', 'CMIP.BCC.BCC-ESM1.historical.Amon.gn', 'CMIP.NCAR.CESM2.historical.Amon.gn'])\n",
      "dict_values([<xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 19, lon: 128, member_id: 1)\n",
      "Coordinates:\n",
      "  * lat        (lat) float64 37.67 40.46 43.25 46.05 ... 79.53 82.31 85.1 87.86\n",
      "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(128, 2), meta=np.ndarray>\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(19, 2), meta=np.ndarray>\n",
      "    plev       float64 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    co2        (member_id, lat, lon) float32 dask.array<chunksize=(1, 19, 128), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 45, lon: 288, member_id: 1)\n",
      "Coordinates:\n",
      "  * lat        (lat) float64 -44.5 -43.5 -42.5 -41.5 ... -3.5 -2.5 -1.5 -0.5\n",
      "  * lon        (lon) float64 0.625 1.875 3.125 4.375 ... 355.6 356.9 358.1 359.4\n",
      "  * bnds       (bnds) float64 1.0 2.0\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(288, 2), meta=np.ndarray>\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(45, 2), meta=np.ndarray>\n",
      "    plev       float64 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Data variables:\n",
      "    co2        (member_id, lat, lon) float32 dask.array<chunksize=(1, 45, 288), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (bnds: 2, lat: 19, lon: 128, member_id: 1)\n",
      "Coordinates:\n",
      "  * lat        (lat) float64 37.67 40.46 43.25 46.04 ... 79.53 82.31 85.1 87.86\n",
      "  * lon        (lon) float64 0.0 2.812 5.625 8.438 ... 348.8 351.6 354.4 357.2\n",
      "    lon_bnds   (lon, bnds) float64 dask.array<chunksize=(128, 2), meta=np.ndarray>\n",
      "    lat_bnds   (lat, bnds) float64 dask.array<chunksize=(19, 2), meta=np.ndarray>\n",
      "    plev       float64 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: bnds\n",
      "Data variables:\n",
      "    co2        (member_id, lat, lon) float32 dask.array<chunksize=(1, 19, 128), meta=np.ndarray>, <xarray.Dataset>\n",
      "Dimensions:    (lat: 45, lon: 288, member_id: 1, nbnd: 2)\n",
      "Coordinates:\n",
      "  * lat        (lat) float64 -47.59 -46.65 -45.71 -44.76 ... -8.01 -7.068 -6.126\n",
      "  * lon        (lon) float64 0.0 1.25 2.5 3.75 5.0 ... 355.0 356.2 357.5 358.8\n",
      "    lon_bnds   (lon, nbnd) float64 dask.array<chunksize=(288, 2), meta=np.ndarray>\n",
      "    lat_bnds   (lat, nbnd) float64 dask.array<chunksize=(45, 2), meta=np.ndarray>\n",
      "    plev       float64 100.0\n",
      "  * member_id  (member_id) <U8 'r1i1p1f1'\n",
      "Dimensions without coordinates: nbnd\n",
      "Data variables:\n",
      "    co2        (member_id, lat, lon) float32 dask.array<chunksize=(1, 45, 288), meta=np.ndarray>])\n"
     ]
    }
   ],
   "source": [
    "print(pct_change.keys())\n",
    "print(pct_change.values())\n",
    "#Note sure why I can't access a specific key...\n",
    "#print(pct_change.key['CMIP.MRI.MRI-ESM2-0.historical.Amon.gn'])\n",
    "#print(pct_change.key['CMIP.NOAA-GFDL.GFDL-ESM4.historical.Amon.gr1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsetting atmosphere level and last 20 years\n",
    "Global data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sim_name, data in co2_ds.items():\n",
    "    co2_ds_lev = data.isel(plev=18, time=slice(145,165))\n",
    "#    print(co2_ds_lev)\n",
    "    co2_ds_mean = co2_ds_lev.mean(dim=[\"time\"])\n",
    "#    print(co2_ds_mean)\n",
    "    co2_ds[sim_name] = co2_ds_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(co2_ds.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weighted means not plotting, so attempting to calculate unweighted global means\n",
    "#unwtd_co2_ds = {}\n",
    "#for sim_name, data in co2_ds.items():\n",
    "#    co2_ds_globavg = data.mean(dim=('lat','lon'))\n",
    "#    print(co2_ds_globavg)\n",
    "#    unwtd_co2_ds[sim_name] = co2_ds_globavg\n",
    "    \n",
    "# Pick lat & lon -- example from Will\n",
    "#tlat = 60  #60, 70 #-5  #46  #-3 \n",
    "#tlon = 240 #240,30 #300 #262 #280 \n",
    "#svdGPP.climatology.sel(lat=tlat, lon=tlon, method='nearest').plot(color='g',lw=3)\n",
    "\n",
    "#will has a loop to plot over points\n",
    "\n",
    "#To get NH value, try:\n",
    "#.sel(lat=slice(30:90),lon=slice())\n",
    "#print(unwtd_co2_ds.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Haven't gotten any of these to work properly...\n",
    "#for sim_name, data in co2_ds.items():\n",
    "#    wtd_co2 = compute_grid_area(data)\n",
    "#    wtd_co2 = gridcell_areas(data.lat, data.lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtd_co2_ds = {}\n",
    "#cosine function from Katie\n",
    "# note that she showed this isn't as good of a weighting metric\n",
    "# using this for now because I can't figure out how to use Matt's weighting functions\n",
    "#for sim_name, data in co2_ds.items():\n",
    "#    lats = data.lat\n",
    "#    cwt = np.cos(lats * np.pi / 180.)\n",
    "#    wtd_co2 = esmlab.statistics.weighted_mean(data, dim=['lat'], weights=cwt).mean().values\n",
    "#    print(wtd_co2)\n",
    "#    wtd_co2_ds[sim_name] = wtd_co2\n",
    "\n",
    "#print(wtd_co2_ds)\n",
    "#why are these all float64???\n",
    "\n",
    "\n",
    "#Another example from Katie -- area element weighting\n",
    "## we know already that the spacing of the points is 4 degrees latitude, 5 degrees longitude\n",
    "R = 6.37e6\n",
    "for sim_name, data in co2_ds.items():\n",
    "    nlat = data.lat\n",
    "    nlon = data.lon\n",
    "    dϕ = np.deg2rad(180./nlat) \n",
    "    dλ = np.deg2rad(360./nlon)\n",
    "    dA = R**2 * dϕ * dλ * np.cos(np.deg2rad(data.lat))\n",
    "    pixel_area = dA.where(data.notnull())\n",
    "    total_land_area = pixel_area.sum(dim=['lat', 'lon'])\n",
    "    ae_wtd_co2amp = ((data * pixel_area).sum(dim=['lat', 'lon']) / total_land_area).values\n",
    "    wtd_co2_ds[sim_name] = ae_wtd_co2amp\n",
    "print(wtd_co2_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_globavg_ds = {}\n",
    "for sim_name, data in co2_ds.items():\n",
    "    glob_avg = data.mean(\"lat\",\"lon\")\n",
    "    co2_globavg_ds[sim_name] = glob_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#maybe the weighting already calculated the means... so this might not be necessary; it doesn't work at least\n",
    "#for sim_name, data in wtd_co2_ds.items():\n",
    "#    global_avg = data.mean(dims=[\"lat\",\"lon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not sure how to properly work with above weights -- looks like it give a float64 value, not sure why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging ensemble means (for when I have multiple members)\n",
    "#### Borrowed from Katie's code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Below code doesn't work\n",
    "ens_mean_co2amp = {}\n",
    "for sim_name, data in wtd_co2_ds.items():\n",
    "#note that mcount doesn't work -- 'function' object has no attribute 'sizes'. Not sure how to solve\n",
    "    mcount = data.sizes['member_id']  # count of ensemble members\n",
    "    ens_mean_co2amp[sim_name + f' (n={mcount})'] = data.mean(dim='member_id', keep_attrs=True).resample(time='AS').mean(keep_attrs=True)\n",
    "#adding var name doesn't seem to solve the problem\n",
    "#    mcount = data.co2.sizes['member_id']  # count of ensemble members\n",
    "#    ens_mean_co2amp[sim_name + f' (n={1})'] = data.co2.mean(dim='member_id', keep_attrs=True).resample(time='AS').mean(keep_attrs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Also borrowed from Katie\n",
    "#need to have above code block working to use this\n",
    "# combine all the members into 1 DataArray\n",
    "#members = xr.DataArray(list(ens_mean_co2amp.keys()), dims='members', name='members')\n",
    "#da = xr.concat(ens_mean_co2amp.values(), dim=members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig 1 - using built-in xarray plotting\n",
    "#fig = plt.figure(figsize=(12, 8))\n",
    "#da.sel(time=slice('2015', '2100')).plot.line(x='time')\n",
    "#plt.title('Projected Changes in Annual Total NBP', fontdict={'size':16})\n",
    "#plt.ylabel('NBP'+' (' + da.attrs['units'] +')');\n",
    "\n",
    "\n",
    "#can't figure out why I can't plot this... \n",
    "#attempting plot below\n",
    "names = list(wtd_co2_ds.keys())\n",
    "values = list(wtd_co2_ds.values())\n",
    "print(len(names))\n",
    "print(values)\n",
    "x = np.arange(len(co2_globavg_ds))\n",
    "\n",
    "print(type(names))\n",
    "print(type(values))\n",
    "print(type(x))\n",
    "\n",
    "print(values)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "#plt.bar(range(len(co2_globavg_ds)),values,tick_label=names)\n",
    "#bar_plot = plt.bar(x,values)\n",
    "#plt.title(\"Average NBP Amplitude for CMIP6 Models (1995-2014)\")\n",
    "\n",
    "#plt.ylabel(\"2m air temperature ($\\degree$C)\")\n",
    "#plt.xticks(x, ('arwt sum','arwt max', 'arwt no norm', 'area no lf', 'cos lat', 'area element', 'area element lf', 'geocat'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting based on Katie's example\n",
    "#fig, ax = plt.subplots(figsize=(12,6))\n",
    "#means = [TSA_glob_mean_arwt_sum, TSA_glob_mean_arwt_max, TSA_glob_mean_arwt, TSA_glob_mean_arwt_nolf, TSA_glob_mean_cwt, TSA_glob_mean_ae, TSA_glob_mean_ae_lf, TSA_glob_mean_geocat]\n",
    "#x = np.arange(len(means))\n",
    "#means_c = [m - 273.15 for m in means]\n",
    "\n",
    "# color code bars based on value - though hard to distinguish close values\n",
    "#from matplotlib import cm\n",
    "#color_vals = np.array(means_c)\n",
    "#colors = cm.hsv(color_vals / float(max(color_vals)))\n",
    "\n",
    "#bar_plot = plt.bar(x,means_c,color = colors)\n",
    "#plt.title(\"Comparing Global Mean Methods\")\n",
    "#plt.ylabel(\"2m air temperature ($\\degree$C)\")\n",
    "#plt.xticks(x, ('arwt sum','arwt max', 'arwt no norm', 'area no lf', 'cos lat', 'area element', 'area element lf', 'geocat'))\n",
    "\n",
    "# add text labels\n",
    "#labels_plot = [round(m, 5) for m in means_c] # round to 4 decimal places\n",
    "#def autolabel(rects):\n",
    "#    for idx,rect in enumerate(bar_plot):\n",
    "#        height = rect.get_height()\n",
    "#        ax.text(rect.get_x() + rect.get_width()/2., 1.02*height,\n",
    "#                labels_plot[idx],\n",
    "#                ha='center', va='bottom', rotation=0)\n",
    "\n",
    "#autolabel(bar_plot)\n",
    "\n",
    "#plt.ylim(0,13);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To Do next\n",
    " - atm level for CO2 (looks like all are standardized at 19 levels)\n",
    " - decide what region (point, global, NH) to get data for, and figure out how to do the appropriate weighting\n",
    "     - note: if just choosing 30N, perhaps the lat/lon weighting Katie tried is enough -- I don't need the \n",
    " - what kind of figure to make? Annual cycle? or just a value?\n",
    " Maybe start with plotting annual cycle for all CMIP6 models N of 30N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val  = co2_ds.get('CMIP.MRI.MRI-ESM2-0.historical.fx.gn')\n",
    "print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CMIP6 2019.10a",
   "language": "python",
   "name": "cmip6-201910a"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
